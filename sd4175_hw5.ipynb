{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Neural Networks (100 points)\n",
    "\n",
    "In this homework, you will be implementing a fully connected neural network and a convolutional neural network using the PyTorch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset (MNIST)\n",
    "\n",
    "We can use some PyTorch DataLoader utilities for this. This will download, shuffle, normalize data and arrange it in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Data\n",
    "\n",
    "You must sample 10 images (one from each class) from the dataset and plot them as a grid with 2 rows of 5 columns each (i.e. of shape `2 x 5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Plot 10 images with one image from each class in the training set\n",
    "images,labels = next(iter(train_loader))\n",
    "npimg= images.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(2, 5))\n",
    "for index in range(0, 10):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.imshow(npimg[index].reshape(28, 28), interpolation='none')\n",
    "    plt.title(\"{}\".format(labels[index]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Fully Connected Neural Network on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network\n",
    "\n",
    "Build a 3-layer fully connected neural network that takes an input of size `784`, outputs `10` classes and has a hidden layer of size `(8,8)`. Use ReLU non-linearity and apply a logSoftmax function on the final layer.\n",
    "\n",
    "The model must have the following architecture:\n",
    "\n",
    "```\n",
    "linear_layer(input_size, n_hidden)\n",
    "relu\n",
    "linear_layer(n_hidden, n_hidden)\n",
    "relu\n",
    "linear_layer(n_hidden, output_size)\n",
    "log_softmax\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(FCN, self).__init__()\n",
    "        # Inputs to hidden layer linear transformation       \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()   \n",
    "        self.hidden1 = nn.Linear(input_size, n_hidden)\n",
    "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.hidden3 = nn.Linear(n_hidden, output_size)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations       \n",
    "        x = self.flatten(x)       \n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.hidden3(x)    \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train and test function\n",
    "\n",
    "Complete the function for training and evaluating the model. You must use the cross entropy loss function for training the model.\n",
    "\n",
    "Note:\n",
    "- `permute` is a function passed as an argument to train and test functions.\n",
    "- `permutation_order` is a 1D torch array of size 784 (=28*28). It contains the random order for permutating the pixels in the `28x28` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, model, optimizer, permute_pixels=None, permutation_order=None):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        epoch (int): current epoch\n",
    "        model (nn.Module): model to train\n",
    "        optimizer (torch.optim): optimizer to use\n",
    "        permute_pixels (function): function to permute the pixels (default: None)\n",
    "        permutation_order (1D torch array): order of the permutation (default: None)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        if permute_pixels is not None:\n",
    "            data = permute_pixels(data, permutation_order)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, permute_pixels=None, permutation_order=None):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to test\n",
    "        permute (function): function to permute the pixels (default: None)\n",
    "        permutation_order (1D torch array): order of the permutation (default: None)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        if permute_pixels is not None:\n",
    "            data = permute_pixels(data, permutation_order)\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += loss_fn(output,target).item() # sum up batch loss                                                               \n",
    "        pred = model(data)  # get the index of the max log-probability                                                                 \n",
    "        correct += (pred.argmax(1)==target).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a function for computing the total parameter count of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    # return number of parameters in model\n",
    "    return sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a small fully-connected network\n",
    "\n",
    "Optimizer : SGD with lr=0.01 and momentum=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6442\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.329760\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.936176\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.254391\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.996215\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.030686\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.567913\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.600678\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.425062\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.413005\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.401139\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "\n",
    "model_fcn = FCN(input_size, n_hidden, output_size)\n",
    "model_fcn.to(device)\n",
    "optimizer = optim.SGD(model_fcn.parameters(), lr=0.01, momentum=0.5) # use SGD with learning rate 0.01 and momentum 0.5\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fcn)))\n",
    "\n",
    "test_accuracy = []\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fcn, optimizer)\n",
    "    test_accuracy.append(test(model_fcn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Convolutional Neural Network (CNN) on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a convolutional neural network with the following architecture to classify the MNIST images.\n",
    "\n",
    "```\n",
    "Conv(\n",
    "    conv2D(input_size, conv_feature, kernel_size=5)\n",
    "    relu()\n",
    "    maxpool2d(kernel_size=2)\n",
    "    conv2d(conv_feature, conv_feature, kernel_size=5)\n",
    "    relu()\n",
    "    maxpool2d(kernel_size=2)\n",
    ")\n",
    "\n",
    "FC(\n",
    "    linear_feature(conv_feature*4*4, fc_feature),\n",
    "    relu(),\n",
    "    linear_feature(fc_feature, output_size),\n",
    "    log_softmax()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, conv_feature, fc_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        #declare self methods\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "        self.input_size = input_size\n",
    "        self.conv_feature = conv_feature\n",
    "        self.fc_feature = fc_feature\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #Conv & FC\n",
    "        self.conv2d1 = nn.Conv2d(input_size, conv_feature, 5)\n",
    "        self.conv2d2 = nn.Conv2d(conv_feature, conv_feature, 5)\n",
    "        self.maxpool2d1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.maxpool2d2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(conv_feature*4*4, fc_feature)\n",
    "        self.fc2 = nn.Linear(fc_feature, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv2d1(x))\n",
    "        x = self.maxpool2d1(x)\n",
    "        x = F.relu(self.conv2d2(x))\n",
    "        x = self.maxpool2d2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.log_softmax(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a ConvNet with the same number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "conv_features = 6 # number of feature maps\n",
    "fc_features = 50\n",
    "input_size = 1\n",
    "\n",
    "model_cnn = CNN(input_size, conv_features, fc_features, output_size) # create CNN model\n",
    "model_cnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(),lr = 0.01, momentum = 0.5)  # use SGD with learning rate 0.01 and momentum 0.5\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "test_accuracy = []\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn, optimizer)\n",
    "    test_accuracy.append(test(model_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Why do you think the ConvNet performs better than the fully connected network even though both have the same number of parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutions are not densely connected, not all input nodes affect all output nodes. This gives convolutional layers more flexibility in learning. Moreover, the number of weights per layer is a lot smaller, which helps a lot with high-dimensional inputs such as image data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if the assumptions are no longer true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a permutation order, permute the pixels of the input image\n",
    "def permute_pixels(data, permutation_order):\n",
    "    \"\"\"\n",
    "    Permute the pixels of the input image\n",
    "    \n",
    "    Args:\n",
    "        data (torch tensor): batch of input images of shape (B, H, W) where B is the batch size, H is the height and W is the width.\n",
    "        permutation_order (1D torch array): order of the permutation\n",
    "    \n",
    "    Returns:\n",
    "        permuted_data (torch tensor): permuted batch of input images of shape (B, 1, H, W)\n",
    "    \"\"\"  \n",
    "    data = data.view(-1, 28*28)\n",
    "    data = data[0:, permutation_order]   \n",
    "    return data.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_order = torch.randperm(28*28)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = permute_pixels(image.clone(), permutation_order)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet with permuted pixels\n",
    "\n",
    "Train and evaluate a ConvNet with permuted pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "conv_features = 6 # number of feature maps\n",
    "fc_features = 50\n",
    "\n",
    "model_cnn = CNN(input_size, conv_features, fc_features, output_size) # create CNN model\n",
    "model_cnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(),lr = 0.01, momentum = 0.5) # use SGD with learning rate 0.01 and momentum 0.5\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn, optimizer, permute_pixels, permutation_order)\n",
    "    test(model_cnn, permute_pixels, permutation_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected with Permuted Pixels\n",
    "\n",
    "Train and evaluate a fully connected network with permuted pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "input_size  = 28*28\n",
    "\n",
    "model_fnn = FCN(input_size, n_hidden, output_size) # create FCN model\n",
    "model_fnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_fnn.parameters(),lr = 0.01, momentum = 0.5) # use SGD with learning rate 0.01 and momentum 0.5\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn, optimizer, permute_pixels)\n",
    "    test(model_fnn, permute_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: We observe that the ConvNet's performance drops when we permute the pixels, but the Fully-Connected Network's performance stays the same. Provide an explanation for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet makes the assumption that pixels lie on a grid and are stationary/local, which means the assumption could influence its results. The assumption might be wrong and leads to decreasing performance. Meanwhile, FCN doesn't make assumptions since it doesn't learn from prior knowledge. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc6f77fc95e5420108aa348103e4498d1d0de016cf7e1fd7da540445454c305d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
